{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet-sentiment-extraction/test.csv',\n",
       " 'tweet-sentiment-extraction/train.csv',\n",
       " 'tweet-sentiment-extraction/sample_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"tweet-sentiment-extraction/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"tweet-sentiment-extraction/train.csv\")\n",
    "test_csv = pd.read_csv(\"tweet-sentiment-extraction/test.csv\")\n",
    "submit = pd.read_csv(\"tweet-sentiment-extraction/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27486 entries, 0 to 27485\n",
      "Data columns (total 4 columns):\n",
      "textID           27486 non-null object\n",
      "text             27485 non-null object\n",
      "selected_text    27485 non-null object\n",
      "sentiment        27486 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 859.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3535 entries, 0 to 3534\n",
      "Data columns (total 3 columns):\n",
      "textID       3535 non-null object\n",
      "text         3535 non-null object\n",
      "sentiment    3535 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 82.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the null item in the train file\n",
    "train_csv = train_csv[~((train_csv['text'].isnull()) | (train_csv['selected_text'].isnull()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11117\n",
       "positive     8582\n",
       "negative     7786\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字典大小： 28996\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "print(\"字典大小：\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert token to id\n",
      "['I', 'have', 'an', 'apple'] ---> [146, 1138, 1126, 12075]\n"
     ]
    }
   ],
   "source": [
    "token = tokenizer.tokenize(\"I have an apple\")\n",
    "print(\"Convert token to id\")\n",
    "print(f\"{token} ---> {tokenizer.convert_tokens_to_ids(token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data remains after selecting: 25810\n"
     ]
    }
   ],
   "source": [
    "# selecting the length of the text is less than 128 or equal to 128\n",
    "MAX_LENGTH = 128\n",
    "train_csv = train_csv[train_csv[\"text\"].apply(lambda x: len(x)) <= MAX_LENGTH]\n",
    "train_csv = train_csv[train_csv[\"selected_text\"].apply(lambda x: len(x)) <= MAX_LENGTH]\n",
    "print(f\"train data remains after selecting: {len(train_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>positive</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>negative</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>positive</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>headache  wanna see my Julie</td>\n",
       "      <td>negative</td>\n",
       "      <td>headache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0      Oh! Good idea about putting them on ice cream  positive   \n",
       "1  says good (or should i say bad?) afternoon!  h...   neutral   \n",
       "2         i dont think you can vote anymore! i tried  negative   \n",
       "3             haha better drunken tweeting you mean?  positive   \n",
       "4                       headache  wanna see my Julie  negative   \n",
       "\n",
       "                                 selected_text  \n",
       "0                                         Good  \n",
       "1  says good (or should i say bad?) afternoon!  \n",
       "2           i dont think you can vote anymore!  \n",
       "3                                       better  \n",
       "4                                     headache  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = train_csv.reset_index()\n",
    "train_csv = train_csv[[\"text\", \"sentiment\", \"selected_text\"]]\n",
    "\n",
    "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
    "train_csv.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測樣本數： 3535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>http://twitpic.com/67swx - i wish i was calli...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha. HOUSE MD marathon ulet</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>I'm concerned for that family</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th February</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  11aa4945ff   http://twitpic.com/67swx - i wish i was calli...  positive\n",
       "1  fd1db57dc0              i'm done.haha. HOUSE MD marathon ulet  positive\n",
       "2  2524332d66                      I'm concerned for that family  positive\n",
       "3  0fb19285b2  HEY GUYS IT'S WORKING NO NEED TO WORRY. i have...  positive\n",
       "4  e6c9e5e3ab                                      26th February   neutral"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"預測樣本數：\", len(test_csv))\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mode, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(self.mode+\".tsv\", sep=\"\\t\")\n",
    "        self.len = len(self.df)\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "    \n",
    "    # token_tensor, segment_tensor, mask_tensor      \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.mode==\"test\":\n",
    "            text = self.df.iloc[idx, :].values\n",
    "        else:\n",
    "            text, sentiment, selected_text = self.df.iloc[idx, [0, 1, 2]].values\n",
    "        \n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        word_pieces += [sentiment, \"[SEP]\"]\n",
    "        len_sentiment = len(word_pieces)\n",
    "        \n",
    "        sel_tok = tokenizer.tokenize(selected_text)\n",
    "        sel_ids = tokenizer.convert_tokens_to_ids(sel_tok)\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        word_pieces += (tokens + [\"[SEP]\"])\n",
    "        len_text = len(word_pieces) - len_sentiment\n",
    "            \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "    \n",
    "        for ind in [i for i, e in enumerate(ids) if e == sel_ids[0]]:\n",
    "            if ids[ind: ind+len(sel_ids)] == sel_ids:\n",
    "                self.start = ind\n",
    "                self.end = ind + len(sel_ids) - 1\n",
    "                break\n",
    "        \n",
    "        laber_tensor = torch.tensor([self.start, self.end]).type(torch.long) if self.mode == \"train\" else None\n",
    "        segments_tensor = torch.tensor([0] * len_sentiment + [1] * len_text, dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, laber_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "trainset = TweetDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1： Oh! Good idea about putting them on ice cream\n",
      "句子 2：positive\n",
      "分類  ：Good\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([ 101, 3112,  102, 2048,  106, 2750, 1911, 1164, 4518, 1172, 1113, 2854,\n",
      "        7081,  102])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "label_tensor   ：tensor([5, 5])\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS] positive [SEP] Oh ! Good idea about putting them on ice cream [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 選擇第一個樣本\n",
    "sample_idx = 0\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "text_a, text_b, label = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \" \".join(tokens)\n",
    "\n",
    "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{text_a}\n",
    "句子 2：{text_b}\n",
    "分類  ：{label}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to divide data into mini-batch\n",
    "from torch.utils.data import DataLoader\n",
    "# make data have the same length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def mini_batch(samples):\n",
    "    token_tensors = [t[0] for t in samples]\n",
    "    segment_tensors = [s[1] for s in samples]\n",
    "\n",
    "    if samples[0][2] is not None:\n",
    "        label_tensors = [l[2] for l in samples]\n",
    "        label_tensors = torch.stack(label_tensors)\n",
    "    else:\n",
    "        label_tensors = None\n",
    "        \n",
    "    token_tensors = pad_sequence(token_tensors, batch_first=True)\n",
    "    segment_tensors = pad_sequence(segment_tensors, batch_first=True)\n",
    "        \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    mask_tensors = torch.zeros(token_tensors.shape, dtype=torch.long)\n",
    "    mask_tensors = mask_tensors.masked_fill(token_tensors != 0, 1)\n",
    "    \n",
    "    return token_tensors, segment_tensors, mask_tensors, label_tensors\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, collate_fn = mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([64, 46]) \n",
      "tensor([[ 101, 3112,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 8795,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 4366,  102,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4366,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 3112,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 8795,  102,  ...,    0,    0,    0]])\n",
      "------------------------\n",
      "segments_tensors.shape = torch.Size([64, 46])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "masks_tensors.shape    = torch.Size([64, 46])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "label_ids.shape        = torch.Size([64, 2])\n",
      "tensor([[ 5,  5],\n",
      "        [ 3, 14],\n",
      "        [ 3, 11],\n",
      "        [ 5,  5],\n",
      "        [ 3,  3],\n",
      "        [ 3,  9],\n",
      "        [ 3,  4],\n",
      "        [ 3,  3],\n",
      "        [ 3, 32],\n",
      "        [ 3, 11],\n",
      "        [ 3,  6],\n",
      "        [ 3, 20],\n",
      "        [ 3, 10],\n",
      "        [ 3, 10],\n",
      "        [ 9, 12],\n",
      "        [ 7,  9],\n",
      "        [ 3, 23],\n",
      "        [ 3, 11],\n",
      "        [ 3,  4],\n",
      "        [ 8, 16],\n",
      "        [ 3,  9],\n",
      "        [ 3, 15],\n",
      "        [14, 14],\n",
      "        [ 3,  7],\n",
      "        [ 3, 37],\n",
      "        [ 3, 37],\n",
      "        [ 3, 23],\n",
      "        [ 3,  7],\n",
      "        [ 7,  8],\n",
      "        [ 3, 10],\n",
      "        [ 3, 10],\n",
      "        [ 3,  7],\n",
      "        [ 5,  5],\n",
      "        [ 3, 12],\n",
      "        [11, 12],\n",
      "        [ 3,  9],\n",
      "        [ 3,  7],\n",
      "        [22, 22],\n",
      "        [ 3,  7],\n",
      "        [ 4,  4],\n",
      "        [ 3,  6],\n",
      "        [ 8, 10],\n",
      "        [ 3, 23],\n",
      "        [ 3,  9],\n",
      "        [ 9, 14],\n",
      "        [18, 27],\n",
      "        [12, 16],\n",
      "        [ 3,  8],\n",
      "        [ 3, 34],\n",
      "        [ 3, 12],\n",
      "        [ 3,  8],\n",
      "        [ 3,  7],\n",
      "        [14, 16],\n",
      "        [ 3,  8],\n",
      "        [20, 22],\n",
      "        [12, 13],\n",
      "        [ 3,  9],\n",
      "        [ 6,  6],\n",
      "        [ 3,  4],\n",
      "        [ 3,  4],\n",
      "        [ 3, 12],\n",
      "        [14, 17],\n",
      "        [10, 10],\n",
      "        [ 3,  9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "# model information: https://huggingface.co/transformers/model_doc/bert.html#bertforquestionanswering\n",
    "model = BertForQuestionAnswering.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": null,\n",
       "  \"do_sample\": false,\n",
       "  \"eos_token_ids\": null,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"is_decoder\": false,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"length_penalty\": 1.0,\n",
       "  \"max_length\": 20,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_beams\": 1,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"num_return_sequences\": 1,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": null,\n",
       "  \"pruned_heads\": {},\n",
       "  \"repetition_penalty\": 1.0,\n",
       "  \"temperature\": 1.0,\n",
       "  \"top_k\": 50,\n",
       "  \"top_p\": 1.0,\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors,\n",
    "                            start_positions=labels[:, 0], \n",
    "                            end_positions=labels[:, 1])\n",
    "            \n",
    "            starts = outputs[0]\n",
    "            ends = outputs[1]\n",
    "            _, starts_pred = torch.max(starts.data, 1)\n",
    "            _, ends_pred = torch.max(ends.data, 1)\n",
    " \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                starts_bool = (starts_pred == labels[:, 0])\n",
    "                ends_bool = (ends_pred == labels[:, 1])\n",
    "                correct += torch.stack([i and k for i, k in zip(starts_bool,  ends_bool)]).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = torch.tensor(zip(starts_pred, ends_pred))\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, torch.tensor(zip(starts_pred, ends_pred))))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "# _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "# print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 訓練模式\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 6  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        token_tensors, segment_tensors, mask_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=token_tensors, \n",
    "                        token_type_ids=segment_tensors, \n",
    "                        attention_mask=mask_tensors, \n",
    "                        start_positions=labels[:, 0], end_positions=labels[:, 1])\n",
    "        \n",
    "        starts = outputs[1].data\n",
    "        ends = outputs[2].data\n",
    "        _, starts_pred = torch.max(starts.data, 1)\n",
    "        _, ends_pred = torch.max(ends.data, 1)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' % (epoch + 1, running_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[2].data.shape)\n",
    "print(outputs[1].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(tokenizer.convert_ids_to_tokens(trainset[0][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "a.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  jaccard --> 聯集分之交集(用於比較兩個集合的相似度)\n",
    "#  lemmatization\n",
    "# [SEP] 102 [CLS] 101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
